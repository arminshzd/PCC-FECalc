{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import botorch\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "from gpytorch.likelihoods import FixedNoiseGaussianLikelihood\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from botorch.acquisition.multi_objective.monte_carlo import qNoisyExpectedHypervolumeImprovement\n",
    "from botorch.optim.optimize import optimize_acqf_discrete\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "import gpytorch\n",
    "\n",
    "from gskgpr import GaussianStringKernelGP\n",
    "from seq2ascii import Seq2Ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REF_POINT = torch.Tensor([-10, -10])\n",
    "gpytorch.settings.debug._set_state(True)\n",
    "botorch.settings.debug._set_state(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_res(pcc, data_dir):\n",
    "    with open(f\"{data_dir}/{pcc}_FEN.JSON\") as f:\n",
    "        rep = json.load(f)\n",
    "    F_fen = rep[\"FE\"]\n",
    "    F_fen_err = rep[\"FE_error\"]\n",
    "\n",
    "    with open(f\"{data_dir}/{pcc}_DEC.JSON\") as f:\n",
    "        rep = json.load(f)\n",
    "    F_dec = rep[\"FE\"]\n",
    "    F_dec_err = rep[\"FE_error\"]\n",
    "    return {\"PCC\": [rep[\"PCC\"]], \"F_FEN\": [float(F_fen)], \"err_FEN\": [float(F_fen_err)],\n",
    "             \"F_DEC\": [float(F_dec)], \"err_DEC\": [float(F_dec_err)]}\n",
    "\n",
    "def load_data(data_dir):\n",
    "    PCC_list = []\n",
    "    for folder in os.listdir(data_dir):\n",
    "        if re.match(\"[A-Z]{5}_[A-Z]{3}\", folder):\n",
    "            PCC_list.append(folder.split(\"_\")[0])\n",
    "\n",
    "    PCC_list = set(PCC_list)\n",
    "    data = []\n",
    "    for pcc in PCC_list:\n",
    "        try:\n",
    "            data.append(pd.DataFrame(load_json_res(pcc, data_dir)))\n",
    "        except:\n",
    "            print(f\"Skipping {pcc}.\")\n",
    "\n",
    "    data = pd.concat(data)\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data(\"/Users/arminsh/Documents/FEN-HTVS/results\")\n",
    "dataset[\"ddG_sen\"] = -1*dataset.F_FEN\n",
    "dataset[\"ddG_spe\"] = dataset.F_DEC-dataset.F_FEN\n",
    "dataset[\"sen_var\"] = dataset.err_FEN\n",
    "dataset[\"spe_var\"] = np.sqrt(dataset.err_FEN**2 + dataset.err_DEC**2)\n",
    "dataset.sen_var = dataset.sen_var/dataset.ddG_sen.std()\n",
    "dataset.ddG_sen = (dataset.ddG_sen - dataset.ddG_sen.mean())/dataset.ddG_sen.std()\n",
    "dataset.spe_var = dataset.spe_var/dataset.ddG_spe.std()\n",
    "dataset.ddG_spe = (dataset.ddG_spe - dataset.ddG_spe.mean())/dataset.ddG_spe.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "translator = Seq2Ascii(\"./AA.blosum62.pckl\")\n",
    "\n",
    "fspace = []\n",
    "with open(\"../gen_input_space/full_space.txt\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        fspace.append(line.split()[0])\n",
    "        line = f.readline()\n",
    "\n",
    "translator.fit(fspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_x = translator.encode_to_int(dataset.PCC.to_list()).to(device)\n",
    "FE_sen = torch.tensor(dataset.ddG_sen.to_numpy()).float().to(device)\n",
    "FE_sen_var = torch.tensor(dataset.sen_var.to_numpy()).float().to(device)\n",
    "FE_spe = torch.tensor(dataset.ddG_spe.to_numpy()).float().to(device)\n",
    "FE_spe_var = torch.tensor(dataset.spe_var.to_numpy()).float().to(device)\n",
    "train_y = torch.cat([FE_sen.view(-1, 1), FE_spe.view(-1, 1)], dim=1)\n",
    "err_y = torch.cat([FE_sen_var.view(-1, 1), FE_spe_var.view(-1, 1)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(train_x, train_y, err_y, translator):\n",
    "    models = [\n",
    "        GaussianStringKernelGP(train_x=train_x, train_y=train_y[:, 0], \n",
    "                            likelihood=FixedNoiseGaussianLikelihood(noise=err_y[:, 0]), \n",
    "                            translator=translator),\n",
    "        GaussianStringKernelGP(train_x=train_x, train_y=train_y[:, 1],\n",
    "                            likelihood=FixedNoiseGaussianLikelihood(noise=err_y[:, 1]), \n",
    "                            translator=translator)\n",
    "    ]\n",
    "    model = ModelListGP(*models).to(device)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model).to(device)\n",
    "    return model, mll\n",
    "\n",
    "def opt_qnehvi_get_obs(model, train_x, choices, sampler):\n",
    "    \n",
    "    acq_func = qNoisyExpectedHypervolumeImprovement(\n",
    "        model=model,\n",
    "        ref_point=REF_POINT,\n",
    "        X_baseline=train_x.view(-1, 1).type(torch.float32),\n",
    "\t    prune_baseline=True,\n",
    "        sampler=sampler,\n",
    "    )\n",
    "\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf_discrete(\n",
    "        acq_function=acq_func,\n",
    "        q=3,\n",
    "        choices=choices,\n",
    "        max_batch_size=500,\n",
    "        unique=True\n",
    "    )\n",
    "    # observe new values\n",
    "    new_x = candidates.detach()\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, mll = initialize_model(encoded_x, train_y, err_y**2, translator) # Botorch uses variance (not error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = list(translator.int2str.keys())\n",
    "for i in dataset.PCC: # remove the ones that are already in the training set\n",
    "    choices.remove(translator.str2int[i])\n",
    "choices = torch.Tensor(choices).view(-1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arminsh/miniconda3/envs/torch2/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:284: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mll.train()\n",
    "model.train()\n",
    "fit_gpytorch_mll(mll)\n",
    "mll.eval()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SobolQMCNormalSampler(sample_shape=torch.Size([1028]))\n",
    "outputs = []\n",
    "new_x = opt_qnehvi_get_obs(model, encoded_x, choices, sampler)\n",
    "print(new_x)\n",
    "print(translator.decode(new_x.squeeze()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
